# ðŸ“„ Persona-Driven Document Intelligence
This project is a CPU-efficient system designed for extracting and ranking the most relevant sections/subsections from a set of documents based on a given persona and their specific job-to-be-done. Built for Adobeâ€™s Hackathon challenge, it operates entirely offline (no internet access at runtime) and respects resource limits (sub-1GB models, <60s runtime).

## ðŸš€ Features

ðŸ” Contextual Relevance Scoring based on persona profiles.

ðŸ“Š Ranking Engine for document sections.

ðŸ’¡ Custom persona.json input support.

âš¡ Optimized for speed and memory (runs within 60s on CPU).

ðŸ³ Dockerized for easy setup & reproducibility.

## ðŸ§  Architecture
```
project-root/
â”‚
â”œâ”€â”€ app/                    # Main application logic
â”‚   â”œâ”€â”€ input/              # Input documents go here
â”‚   â”œâ”€â”€ output/             # Outputs final ranked sections
â”‚   â”œâ”€â”€ models/             # Local HuggingFace models
â”‚   â”œâ”€â”€ main.py             # Entry point script
â”‚   â”œâ”€â”€ parser.py           # Document parsing logic
â”‚   â”œâ”€â”€ ranker.py           # Ranking algorithm logic
â”‚   â””â”€â”€ persona.json        # Persona input file
â”‚
â”œâ”€â”€ output/                 # Final exported results (outside container)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

## ðŸ”„ Pipeline Overview

Hereâ€™s a step-by-step breakdown of the document intelligence pipeline:

### 1. Input Collection
Accepts PDF or plain text files from the app/input folder.

Persona description (role + JTBD) is loaded from app/persona.json.

### 2. Parsing
PDFs are converted to text using pdfminer.

Large documents are split into manageable, semantically meaningful chunks (e.g., paragraph blocks).

### 3. Summarization
Each chunk is passed through a local summarization model (e.g., flan-t5-base or similar) to reduce size while preserving core meaning.

This improves scoring accuracy and speed.

### 4. Embedding + Scoring
Summarized chunks are converted into vector embeddings using a sentence transformer model.

The persona query is also embedded.

Cosine similarity is computed between the persona query and each chunk to get a relevance score.

### 5. Ranking
Chunks are sorted in descending order of similarity scores.

Top-k relevant chunks are selected (configurable).

## ðŸ‹ Run with Docker

### 1. Build the Docker image:
```
docker build -t persona-pdf-ranker .
```
### 2.Run the container:
```
docker run --rm -v $(pwd)/app/input:/app/input \
                  -v $(pwd)/app/output:/app/output \
                  -v $(pwd)/app/models:/app/models \
                  -v $(pwd)/output:/output \
                  persona-pdf-ranker
```

## ðŸ§¾ Inputs
**persona.json:** Defines persona traits and job-to-be-done.

.txt or .pdf documents in the /app/input folder.

## ðŸ“¤ Output

Ranked sections (JSON/CSV/text) written to /output.
